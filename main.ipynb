{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama server is now running in the background.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Startet `ollama serve` im Hintergrund\n",
    "process = subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print(\"Ollama server is now running in the background.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lege das LLM fest, mit dem nachfolgend gearbeitet wird.\n",
    "model = \"qwen2.5:7b\"\n",
    "model_custom = \"custom_qwen2.5:7b_seed_42_temp_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Code to create a model with both seed and temperature set in the Modelfile\n",
    "\n",
    "# Define the content of the Modelfile with a specified model, seed, and temperature\n",
    "seed_value = 42  # Example seed value for reproducible results\n",
    "temperature_value = 0  # Setting temperature to 0 for deterministic output\n",
    "\n",
    "# Modelfile content with seed and temperature parameters\n",
    "modelfile_content = f\"FROM {model}\\nPARAMETER seed {seed_value}\\nPARAMETER temperature {temperature_value}\\n\"\n",
    "\n",
    "# Write the content to a Modelfile\n",
    "modelfile_path = \"Modelfile\"  # Path to save the Modelfile in the current directory\n",
    "\n",
    "with open(modelfile_path, \"w\") as modelfile:\n",
    "    modelfile.write(modelfile_content)\n",
    "\n",
    "# Command to create the model using the modified Modelfile\n",
    "command = [\"ollama\", \"create\", \"custom_qwen2.5:7b_seed_42_temp_0\", \"-f\", modelfile_path]\n",
    "\n",
    "# Run the command to create the model\n",
    "try:\n",
    "    result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "    print(result.stdout)  # Print standard output if successful\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"An error occurred:\", e.stderr)  # Display any error messages if the command fails\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: 'ollama' command not found. Ensure that the Ollama CLI is installed and accessible.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Befehl als Liste definieren\n",
    "command = [\"ollama\", \"create\", \"custom_qwen2.5:7b_seed_42\", \"-f\", \"Modelfile\"]\n",
    "\n",
    "# Befehl ausführen und Ausgabe anzeigen\n",
    "try:\n",
    "    result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "    print(result.stdout)  # Gibt die Standardausgabe aus, falls erfolgreich\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Ein Fehler ist aufgetreten:\", e.stderr)  # Zeigt eventuelle Fehlermeldungen an\n",
    "except FileNotFoundError:\n",
    "    print(\"FEHLER: 'ollama'-Befehl wurde nicht gefunden. Bitte sicherstellen, dass die Ollama-CLI installiert und im Pfad verfügbar ist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error: \u001b[?25lpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 2bada8a74506... 100% ▕████████████████▏ 4.7 GB                         \n",
      "pulling 66b9ea09bd5b... 100% ▕████████████████▏   68 B                         \n",
      "pulling eb4402837c78... 100% ▕████████████████▏ 1.5 KB                         \n",
      "pulling 832dd9e00a68... 100% ▕████████████████▏  11 KB                         \n",
      "pulling 2f15b3218f05... 100% ▕████████████████▏  487 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gewähltes Modell von Ollama herunterladen\n",
    "process = subprocess.Popen([\"ollama\", \"pull\", model], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "# Ausgabe anzeigen\n",
    "stdout, stderr = process.communicate()\n",
    "print(stdout.decode(\"utf-8\"))\n",
    "\n",
    "if stderr:\n",
    "    print(\"Error:\", stderr.decode(\"utf-8\"))\n",
    "else:\n",
    "    print(f\"{model} pulled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV-Dateien wurden erfolgreich im 'tables'-Ordner gespeichert.\n"
     ]
    }
   ],
   "source": [
    "import faker\n",
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Seed setzen für Reproduzierbarkeit\n",
    "random.seed(42)\n",
    "Faker.seed(42)\n",
    "fake = Faker()\n",
    "\n",
    "# Ordner 'tables' erstellen, falls nicht vorhanden\n",
    "output_folder = \"tables\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Funktion, um zufällige Datumswerte zu erzeugen\n",
    "def random_date(start, end):\n",
    "    return start + timedelta(days=random.randint(0, (end - start).days))\n",
    "\n",
    "# Anzahl der Datensätze\n",
    "num_students = 100\n",
    "num_courses = 10\n",
    "num_professors = 5\n",
    "num_departments = 3\n",
    "num_enrollments = 300\n",
    "\n",
    "# 1. STUDENT_DIMENSION - Generierung der Studentendaten\n",
    "student_data = {\n",
    "    \"Student_ID\": range(1, num_students + 1),\n",
    "    \"First_Name\": [fake.first_name() for _ in range(num_students)],\n",
    "    \"Last_Name\": [fake.last_name() for _ in range(num_students)],\n",
    "    \"Date_of_Birth\": [random_date(datetime(1990, 1, 1), datetime(2002, 12, 31)).date() for _ in range(num_students)],\n",
    "    \"Enrollment_Date\": [random_date(datetime(2020, 1, 1), datetime(2023, 12, 31)).date() for _ in range(num_students)]\n",
    "}\n",
    "\n",
    "# Erstellung des DataFrames\n",
    "student_df = pd.DataFrame(student_data)\n",
    "\n",
    "# E-Mail-Adresse basierend auf First_Name und Last_Name generieren; wenn hier nochmal random verwendet wird, erhalten wir sonst abweichende Namen in der Mailadresse.\n",
    "student_df[\"Email\"] = student_df[\"First_Name\"].str.lower() + \".\" + student_df[\"Last_Name\"].str.lower() + \"@example.com\"\n",
    "\n",
    "# 2. COURSE_DIMENSION - Generierung der Kursdaten\n",
    "course_names = [\n",
    "    \"Data Science Basics\", \"Advanced Machine Learning\", \"Database Systems\",\n",
    "    \"Statistics for Data Science\", \"Programming with Python\", \"Ethics in AI\",\n",
    "    \"Big Data Analysis\", \"Data Visualization\", \"Project Management\", \"Deep Learning\"\n",
    "]\n",
    "course_data = {\n",
    "    \"Course_ID\": range(1, num_courses + 1),\n",
    "    \"Course_Name\": course_names,\n",
    "    \"Credits\": [random.choice([3, 4, 5]) for _ in range(num_courses)],\n",
    "    \"Department_ID\": [random.randint(1, num_departments) for _ in range(num_courses)]\n",
    "}\n",
    "course_df = pd.DataFrame(course_data)\n",
    "\n",
    "# 3. PROFESSOR_DIMENSION - Generierung der Professorendaten\n",
    "professor_data = {\n",
    "    \"Professor_ID\": range(1, num_professors + 1),\n",
    "    \"First_Name\": [fake.first_name() for _ in range(num_professors)],\n",
    "    \"Last_Name\": [fake.last_name() for _ in range(num_professors)],\n",
    "    \"Email\": [f\"{fake.first_name().lower()}.{fake.last_name().lower()}@university.com\" for _ in range(num_professors)]\n",
    "}\n",
    "professor_df = pd.DataFrame(professor_data)\n",
    "\n",
    "# 4. DEPARTMENT_DIMENSION - Generierung der Abteilungsdaten\n",
    "department_names = [\"Computer Science\", \"Business Administration\", \"Psychology\"]\n",
    "department_data = {\n",
    "    \"Department_ID\": range(1, num_departments + 1),\n",
    "    \"Department_Name\": department_names\n",
    "}\n",
    "department_df = pd.DataFrame(department_data)\n",
    "\n",
    "# 5. ENROLLMENT_FACTS - Generierung der Einschreibungen\n",
    "enrollment_data = {\n",
    "    \"Enrollment_ID\": range(1, num_enrollments + 1),\n",
    "    \"Student_ID\": [random.randint(1, num_students) for _ in range(num_enrollments)],\n",
    "    \"Course_ID\": [random.randint(1, num_courses) for _ in range(num_enrollments)],\n",
    "    \"Professor_ID\": [random.randint(1, num_professors) for _ in range(num_enrollments)],\n",
    "    \"Enrollment_Date\": [random_date(datetime(2021, 1, 1), datetime(2023, 12, 31)).date() for _ in range(num_enrollments)],\n",
    "    \"Grade\": [random.choice(['A', 'B', 'C', 'D', 'F']) for _ in range(num_enrollments)]\n",
    "}\n",
    "enrollment_df = pd.DataFrame(enrollment_data)\n",
    "\n",
    "# Speichern der DataFrames als CSV-Dateien im 'tables'-Ordner\n",
    "student_df.to_csv(os.path.join(output_folder, \"STUDENT_DIMENSION.csv\"), index=False)\n",
    "course_df.to_csv(os.path.join(output_folder, \"COURSE_DIMENSION.csv\"), index=False)\n",
    "professor_df.to_csv(os.path.join(output_folder, \"PROFESSOR_DIMENSION.csv\"), index=False)\n",
    "department_df.to_csv(os.path.join(output_folder, \"DEPARTMENT_DIMENSION.csv\"), index=False)\n",
    "enrollment_df.to_csv(os.path.join(output_folder, \"ENROLLMENT_FACTS.csv\"), index=False)\n",
    "\n",
    "print(\"CSV-Dateien wurden erfolgreich im 'tables'-Ordner gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " STUDENT_DIMENSION\n",
      "\n",
      "|   Student_ID | First_Name   | Last_Name   | Date_of_Birth   | Enrollment_Date   | Email                        |\n",
      "|-------------:|:-------------|:------------|:----------------|:------------------|:-----------------------------|\n",
      "|            1 | Danielle     | Smith       | 1992-07-01      | 2022-01-11        | danielle.smith@example.com   |\n",
      "|            2 | Angel        | Le          | 1990-07-24      | 2021-03-25        | angel.le@example.com         |\n",
      "|            3 | Joshua       | Maldonado   | 1996-03-03      | 2020-10-10        | joshua.maldonado@example.com |\n",
      "|            4 | Jeffrey      | Herrera     | 1995-06-30      | 2022-11-09        | jeffrey.herrera@example.com  |\n",
      "|            5 | Jill         | Adams       | 1995-01-03      | 2022-10-07        | jill.adams@example.com       |\n",
      "\n",
      "\n",
      "\n",
      " COURSE_DIMENSION\n",
      "\n",
      "|   Course_ID | Course_Name                 |   Credits |   Department_ID |\n",
      "|------------:|:----------------------------|----------:|----------------:|\n",
      "|           1 | Data Science Basics         |         3 |               1 |\n",
      "|           2 | Advanced Machine Learning   |         5 |               2 |\n",
      "|           3 | Database Systems            |         3 |               1 |\n",
      "|           4 | Statistics for Data Science |         3 |               3 |\n",
      "|           5 | Programming with Python     |         3 |               1 |\n",
      "\n",
      "\n",
      "\n",
      " PROFESSOR_DIMENSION\n",
      "\n",
      "|   Professor_ID | First_Name   | Last_Name   | Email                            |\n",
      "|---------------:|:-------------|:------------|:---------------------------------|\n",
      "|              1 | Tanya        | Lewis       | joseph.bowers@university.com     |\n",
      "|              2 | Sara         | Morales     | spencer.henderson@university.com |\n",
      "|              3 | Melinda      | Brown       | susan.cowan@university.com       |\n",
      "|              4 | Gabriel      | Gray        | angela.higgins@university.com    |\n",
      "|              5 | Todd         | Galloway    | eric.phillips@university.com     |\n",
      "\n",
      "\n",
      "\n",
      " DEPARTMENT_DIMENSION\n",
      "\n",
      "|   Department_ID | Department_Name         |\n",
      "|----------------:|:------------------------|\n",
      "|               1 | Computer Science        |\n",
      "|               2 | Business Administration |\n",
      "|               3 | Psychology              |\n",
      "\n",
      "\n",
      "\n",
      " ENROLLMENT_FACTS\n",
      "\n",
      "|   Enrollment_ID |   Student_ID |   Course_ID |   Professor_ID | Enrollment_Date   | Grade   |\n",
      "|----------------:|-------------:|------------:|---------------:|:------------------|:--------|\n",
      "|               1 |           17 |           4 |              5 | 2022-08-12        | F       |\n",
      "|               2 |           93 |           6 |              3 | 2022-04-11        | F       |\n",
      "|               3 |           74 |           7 |              3 | 2021-07-05        | A       |\n",
      "|               4 |           74 |           2 |              4 | 2023-06-08        | A       |\n",
      "|               5 |           61 |           6 |              3 | 2021-07-21        | B       |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Namen für die DataFrames zur besseren Darstellung\n",
    "dataframe_names = [\"STUDENT_DIMENSION\", \"COURSE_DIMENSION\", \"PROFESSOR_DIMENSION\", \"DEPARTMENT_DIMENSION\", \"ENROLLMENT_FACTS\"]\n",
    "\n",
    "list_of_dataframes = [student_df, course_df, professor_df, department_df, enrollment_df]\n",
    "\n",
    "# Ausgabe jeder Tabelle als Markdown-Tabelle\n",
    "for name, df in zip(dataframe_names, list_of_dataframes):\n",
    "    print(f\"\\n {name}\\n\")\n",
    "    print(df.head().to_markdown(index=False))  # Ausgabe der ersten fünf Zeilen jeder Tabelle im Markdown-Format\n",
    "    print(\"\\n\")  # Leerzeile für bessere Lesbarkeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                ID              SIZE      MODIFIED       \n",
      "qwen2.5:7b                          845dbda0ea48    4.7 GB    14 seconds ago    \n",
      "custom_qwen2.5:7b_seed_42           2849624f7fb4    4.7 GB    15 seconds ago    \n",
      "custom_qwen2.5:7b_seed_42_temp_0    2849624f7fb4    4.7 GB    15 seconds ago    \n",
      "\n",
      "Available models listed successfully.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# List available models in Ollama\n",
    "process = subprocess.Popen([\"ollama\", \"list\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "# Ausgabe anzeigen\n",
    "stdout, stderr = process.communicate()\n",
    "print(stdout.decode(\"utf-8\"))\n",
    "\n",
    "if stderr:\n",
    "    print(\"Error:\", stderr.decode(\"utf-8\"))\n",
    "else:\n",
    "    print(\"Available models listed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.variables import database_schema_mermaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprompt = \"Your task is to generate executable SQL queries based on my provided model. Please adhere strictly to my model. For each of my questions, generate an executable SELECT SQL query. Do not provide any comments or explanations, only the query. Give me only one query per Question, make sure to start the query with 'SELECT' and end it with a ';'. I am using a sqllite-Database.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fachfrage = \"Welche Studenten haben am häufigsten die Note 'A' erhalten? Gib mir eine absteigend sortierte Liste der Namen und Anzahl für die Top 10.\" # input(\"Bitte gib eine Frage ein, für die eine SQL-Abfrage generiert werden soll: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"{database_schema_mermaid} {preprompt} {fachfrage}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I understand you're feeling disappointed with Mr. Schlieter regarding your study project, but perhaps trying to communicate directly or seeking feedback could help improve your perspective and relationship.\n",
      "ERROR: \u001b[?25l⠙ \u001b[?25h\u001b[?25l\u001b[?25l\u001b[2K\u001b[1G\u001b[?25h\u001b[2K\u001b[1G\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\u001b[?25l\u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Startet `ollama run` und übergibt den Prompt über stdin\n",
    "process = subprocess.Popen(\n",
    "    [\"ollama\", \"run\", model_custom],\n",
    "    stdin=subprocess.PIPE,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE)\n",
    "\n",
    "# Senden des Prompts über stdin und Warten auf die Antwort\n",
    "stdout, stderr = process.communicate(input=prompt.encode())\n",
    "\n",
    "# Ausgabe der Antwort und eventuelle Fehler anzeigen\n",
    "print(stdout.decode().strip())\n",
    "if stderr:\n",
    "    print(\"ERROR:\", stderr.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functions import extract_sql_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No SQL statement found.\n"
     ]
    }
   ],
   "source": [
    "# Funktion, die den Output des Modells so trimmt, dass nur das SQL-Statement stehen bleibt.\n",
    "from src.functions import extract_sql_statement\n",
    "\n",
    "# Beispielaufruf\n",
    "output = stdout.decode()\n",
    "\n",
    "# Anwenden der Extraktionsfunktion\n",
    "trimmed_output = extract_sql_statement(output)\n",
    "print(trimmed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabellen wurden erfolgreich erstellt.\n"
     ]
    }
   ],
   "source": [
    "from src.functions import create_tables\n",
    "\n",
    "# Datenbank und Tabellen erstellen\n",
    "create_tables('university_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbindung und Cursor erstellen\n",
    "conn = sqlite3.connect('university_database.db')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('COURSE_DIMENSION',), ('DEPARTMENT_DIMENSION',), ('ENROLLMENT_FACTS',), ('PROFESSOR_DIMENSION',), ('STUDENT_DIMENSION',)]\n"
     ]
    }
   ],
   "source": [
    "# Zeige alle Tabellen in der Datenbank an\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functions import import_csv_to_sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functions import import_all_csv_to_sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importiert: COURSE_DIMENSION\n",
      "Tabelle 'COURSE_DIMENSION' wurde aus 'COURSE_DIMENSION.csv' importiert.\n",
      "Importiert: DEPARTMENT_DIMENSION\n",
      "Tabelle 'DEPARTMENT_DIMENSION' wurde aus 'DEPARTMENT_DIMENSION.csv' importiert.\n",
      "Importiert: ENROLLMENT_FACTS\n",
      "Tabelle 'ENROLLMENT_FACTS' wurde aus 'ENROLLMENT_FACTS.csv' importiert.\n",
      "Importiert: PROFESSOR_DIMENSION\n",
      "Tabelle 'PROFESSOR_DIMENSION' wurde aus 'PROFESSOR_DIMENSION.csv' importiert.\n",
      "Importiert: STUDENT_DIMENSION\n",
      "Tabelle 'STUDENT_DIMENSION' wurde aus 'STUDENT_DIMENSION.csv' importiert.\n"
     ]
    }
   ],
   "source": [
    "# Beispielaufruf für den Ordner \"tables\" und eine persistente Datenbank\n",
    "import_all_csv_to_sqlite('tables', db_name='university_database.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "near \"No\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Führe die Abfrage aus\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrimmed_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDas Ergebnis der generierten SQL-Abfrage lautet:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Lade die Daten in ein DataFrame\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: near \"No\": syntax error"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Führe die Abfrage aus\n",
    "cursor.execute(trimmed_output)\n",
    "\n",
    "print('Das Ergebnis der generierten SQL-Abfrage lautet:\\n')\n",
    "\n",
    "# Lade die Daten in ein DataFrame\n",
    "df = pd.DataFrame(cursor.fetchall(), columns=[description[0] for description in cursor.description])\n",
    "\n",
    "# DataFrame anzeigen\n",
    "print(df)\n",
    "print(f'\\n\\nDie hierfür generierte SQL-Abfrage lautet:\\n\\n{trimmed_output}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
